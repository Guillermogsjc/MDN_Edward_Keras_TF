{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the [previous blog post](http://cbonnett.github.io/MDN.html) we looked at what a Mixture Density Network is with an implementation in TensorFlow. We then used this to learn the distance to galaxies on a simulated data set. In this blog post we'll show an easier way to code up an MDN by combining the power of three python libraries.\n",
    "\n",
    "1. [Edward](https://github.com/blei-lab/edward)\n",
    "2. [Keras](http://keras.io/) \n",
    "3. [TensorFlow](http://tensorflow.org) \n",
    "\n",
    "You are likely familiar with number 2 and 3 so let me tell you a bit about the first. Edward is a python library\n",
    "for probabilistic modelling, inference, and criticism. It's goal it to fuse the related areas of Bayesian Statistics, Machine Learning, Deep Learning and Probabilistic Programming. Edward is developed by the group of [David Blei](http://www.cs.columbia.edu/~blei/) at Columbia University with the main developer being [Dustin Tran](https://twitter.com/dustinvtran). The example we discuss here is based on the [example](https://github.com/blei-lab/edward/blob/master/examples/mixture_density_network.py) in the Edward repo that was written by Dustin and [myself](https://twitter.com/cbonnett). \n",
    " \n",
    "Edward implements many probability distribution functions that are TensorFlow compatible, this makes it attractive to use for MDN's. In the [previous blog post](http://cbonnett.github.io/MDN.html) we had to roll our own $Beta$ distribution, with Edward this is no longer necessary. Keep in mind, if you want to use Keras and TensorFlow like we will do in this post you need to set the backend of Keras to TensorFlow, [here](http://keras.io/backend/) it is explained how to do that.\n",
    "\n",
    "Here are all the distributions that are currently implemented in Edward, there are more to come:\n",
    "\n",
    "1. [Bernoulli](https://github.com/blei-lab/edward/blob/master/edward/stats/distributions.py#L49)\n",
    "2. [Beta](https://github.com/blei-lab/edward/blob/master/edward/stats/distributions.py#L58)\n",
    "3. [Binomial](https://github.com/blei-lab/edward/blob/master/edward/stats/distributions.py#L68)\n",
    "4. [Chi Squared](https://github.com/blei-lab/edward/blob/master/edward/stats/distributions.py#L79)\n",
    "5. [Dirichlet](https://github.com/blei-lab/edward/blob/master/edward/stats/distributions.py#L89)\n",
    "6. [Exponential](https://github.com/blei-lab/edward/blob/master/edward/stats/distributions.py#L109)\n",
    "7. [Gamma](https://github.com/blei-lab/edward/blob/master/edward/stats/distributions.py#L118)\n",
    "8. [Geometric](https://github.com/blei-lab/edward/blob/master/edward/stats/distributions.py#L129)\n",
    "9. [Inverse Gamma](https://github.com/blei-lab/edward/blob/master/edward/stats/distributions.py#L138)\n",
    "10. [log Normal](https://github.com/blei-lab/edward/blob/master/edward/stats/distributions.py#L155)\n",
    "11. [Multinomial](https://github.com/blei-lab/edward/blob/master/edward/stats/distributions.py#L165)\n",
    "12. [Multivariate Normal](https://github.com/blei-lab/edward/blob/master/edward/stats/distributions.py#L194)\n",
    "13. [Negative Binomial](https://github.com/blei-lab/edward/blob/master/edward/stats/distributions.py#L283)\n",
    "14. [Normal](https://github.com/blei-lab/edward/blob/master/edward/stats/distributions.py#L294)\n",
    "15. [Poisson](https://github.com/blei-lab/edward/blob/master/edward/stats/distributions.py#L310)\n",
    "16. [Student-t](https://github.com/blei-lab/edward/blob/master/edward/stats/distributions.py#L319)\n",
    "17. [Truncated Normal](https://github.com/blei-lab/edward/blob/master/edward/stats/distributions.py#L333)\n",
    "18. [Uniform](https://github.com/blei-lab/edward/blob/master/edward/stats/distributions.py#L352)\n",
    "\n",
    "Which all can be used to make a Mixture Density Networks. Let start by doing the imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import edward as ed\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from edward.stats import norm # normal distribution from Edward ! \n",
    "from keras import backend as K\n",
    "from keras.layers import Dense\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make some toy-data to play with.\n",
    "\n",
    "This is the same toy-data problem set as used in the [blog post](http://blog.otoro.net/2015/11/24/mixture-density-networks-with-tensorflow/) by Otoro where he explains MDNs. This is an inverse problem as you can see, for every ```X``` there are multiple possible ```y``` solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of features in training data: (4000, 1)\n",
      "Size of output in training data: (4000, 1)\n",
      "Size of features in test data: (36000, 1)\n",
      "Size of output in test data: (36000, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x112680f90>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAECCAYAAADw0Rw8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f88e910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_toy_dataset(nsample=40000):\n",
    "    y_data = np.float32(np.random.uniform(-10.5, 10.5, (1, nsample))).T\n",
    "    r_data = np.float32(np.random.normal(size=(nsample,1))) # random noise\n",
    "    x_data = np.float32(np.sin(0.75*y_data)*7.0+y_data*0.5+r_data*1.0)\n",
    "    return train_test_split(x_data, y_data, random_state=42, train_size=0.1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = build_toy_dataset()\n",
    "print(\"Size of features in training data: {:s}\".format(X_train.shape))\n",
    "print(\"Size of output in training data: {:s}\".format(y_train.shape))\n",
    "print(\"Size of features in test data: {:s}\".format(X_test.shape))\n",
    "print(\"Size of output in test data: {:s}\".format(y_test.shape))\n",
    "\n",
    "sns.regplot(X_train, y_train, fit_reg=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a MDN using Edward, Keras and TF\n",
    "\n",
    "We will define a class that can be used to construct MDNs. In this notebook we will be using a mixture of Normal Distributions. The advantage of defining a class is that we can easily reuse this to build other MDNs with different amount of mixture components. Furthermore, this makes it play nice with Edward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MixtureDensityNetwork:\n",
    "    \"\"\"\n",
    "    Mixture density network for outputs y on inputs x.\n",
    "    p((x,y), (z,theta))\n",
    "    = sum_{k=1}^K pi_k(x; theta) Normal(y; mu_k(x; theta), sigma_k(x; theta))\n",
    "    where pi, mu, sigma are the output of a neural network taking x\n",
    "    as input and with parameters theta. There are no latent variables\n",
    "    z, which are hidden variables we aim to be Bayesian about.\n",
    "    \"\"\"\n",
    "    def __init__(self, K):\n",
    "        self.K = K # here K is the amount of Mixtures \n",
    "\n",
    "    def mapping(self, X):\n",
    "        \"\"\"pi, mu, sigma = NN(x; theta)\"\"\"\n",
    "        hidden1 = Dense(15, activation='relu')(X)  # fully-connected layer with 15 hidden units\n",
    "        hidden2 = Dense(15, activation='relu')(hidden1) \n",
    "        self.mus = Dense(self.K)(hidden2) # the means \n",
    "        self.sigmas = Dense(self.K, activation=K.exp)(hidden2) # the variance\n",
    "        self.pi = Dense(self.K, activation=K.softmax)(hidden2) # the mixture components\n",
    "\n",
    "    def log_prob(self, xs, zs=None):\n",
    "        \"\"\"log p((xs,ys), (z,theta)) = sum_{n=1}^N log p((xs[n,:],ys[n]), theta)\"\"\"\n",
    "        # Note there are no parameters we're being Bayesian about. The\n",
    "        # parameters are baked into how we specify the neural networks.\n",
    "        X, y = xs\n",
    "        self.mapping(X)\n",
    "        result = tf.exp(norm.logpdf(y, self.mus, self.sigmas))\n",
    "        result = tf.mul(result, self.pi)\n",
    "        result = tf.reduce_sum(result, 1)\n",
    "        result = tf.log(result)\n",
    "        return tf.reduce_sum(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can set a seed in Edward so we can reproduce all the random components. The following line:\n",
    "\n",
    "```ed.set_seed(42)```\n",
    "\n",
    "sets the seed in Numpy and TensorFlow under the [hood](https://github.com/blei-lab/edward/blob/master/edward/util.py#L191). We use the class we defined above to initiate the MDN with 20 mixtures, this now can be used as an Edward model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ed.set_seed(42)\n",
    "model = MixtureDensityNetwork(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code cell we define the TensorFlow placeholders that are then used to define the Edward data model.\n",
    "The following line passes the ```model``` and ```data``` to ```MAP``` from Edward which is then used to initialise the TensorFlow variables. \n",
    "\n",
    "```inference = ed.MAP(model, data)``` \n",
    "\n",
    "MAP is a Bayesian concept and stands for Maximum A Posteriori, it tries to find the set of parameters which maximizes the posterior distribution. In the example here we don't have a prior, in a Bayesian context this means we have a flat prior. For a flat prior MAP is equivalent to Maximum Likelihood Estimation. Edward is designed to be Bayesian about its statistical inference. The cool thing about MDN's with Edward is that we could easily include priors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.Session at 0x10ff1bc10>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "data = ed.Data([X, y]) # Make Edward Data model\n",
    "\n",
    "inference = ed.MAP(model, data) # Make the inference model\n",
    "sess = tf.Session() # start TF session \n",
    "K.set_session(sess) # pass session info to Keras\n",
    "inference.initialize(sess=sess) # initialize all TF variables using the Edward interface "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having done that we can train the MDN in TensorFlow just like we normally would, and we can get out the predictions we are interested in from ```model```, in this case: \n",
    "\n",
    "* ```model.pi``` the mixture components, \n",
    "* ```model.mus``` the means,\n",
    "* ```model.sigmas``` the standard  deviations.   \n",
    "\n",
    "This is done in the last line of the code cell :\n",
    "```\n",
    "pred_weights, pred_means, pred_std = sess.run([model.pi, model.mus, model.sigmas], \n",
    "                                              feed_dict={X: X_test})\n",
    "```\n",
    "\n",
    "The default minimisation technique used is ADAM with a decaying scale factor.\n",
    "This can be seen [here](https://github.com/blei-lab/edward/blob/master/edward/inferences.py#L94) in the code base of Edward. Having a decaying scale factor is not the standard way of using ADAM, this is inspired by the Automatic Differentiation Variational Inference [(ADVI)](http://arxiv.org/abs/1603.00788) work where it was used in the RMSPROP minimizer.      \n",
    "\n",
    "The loss that is minimised in the ```MAP``` model from Edward is the negative log-likelihood, this calculation uses the  ```log_prob``` method in the ```MixtureDensityNetwork``` class we defined above. \n",
    "The ```build_loss``` method in the ```MAP``` class can be found [here](https://github.com/blei-lab/edward/blob/master/edward/inferences.py#L396). \n",
    "\n",
    "However the method ```inference.loss``` used below, returns the log-likelihood, so we expect this quantity to be maximized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NEPOCH = 1000\n",
    "train_loss = np.zeros(NEPOCH)\n",
    "test_loss = np.zeros(NEPOCH)\n",
    "for i in range(NEPOCH):\n",
    "    _, train_loss[i] = sess.run([inference.train, inference.loss],\n",
    "                                feed_dict={X: X_train, y: y_train})\n",
    "    test_loss[i] = sess.run(inference.loss, feed_dict={X: X_test, y: y_test})\n",
    "    \n",
    "pred_weights, pred_means, pred_std = sess.run([model.pi, model.mus, model.sigmas], \n",
    "                                              feed_dict={X: X_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the log-likelihood of the training and test sample as function of training epoch.\n",
    "Keep in mind that ```inference.loss``` returns the total log-likelihood, so not the loss per data point, so in the plotting routine we divide by the size of the train and test data respectively. \n",
    "We see that it converges after 400 training steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(16, 3.5))\n",
    "plt.plot(np.arange(NEPOCH), test_loss/len(X_test), label='Test')\n",
    "plt.plot(np.arange(NEPOCH), train_loss/len(X_train), label='Train')\n",
    "plt.legend(fontsize=20)\n",
    "plt.xlabel('Epoch', fontsize=15)\n",
    "plt.ylabel('Log-likelihood', fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can have a look at how some individual examples perform. Keep in mind this is an inverse problem\n",
    "so we can't get the answer correct, we can hope that the truth lies in area where the model has high probability.\n",
    "In the next plot the truth is the vertical grey line while the blue line is the prediction of the mixture density network. As you can see, we didn't do too bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "obj = [0, 4, 6]\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(16, 6))\n",
    "\n",
    "plot_normal_mix(pred_weights[obj][0], pred_means[obj][0], pred_std[obj][0], \n",
    "                axes[0], comp=False)\n",
    "axes[0].axvline(x=y_test[obj][0], color='black', alpha=0.5)\n",
    "\n",
    "plot_normal_mix(pred_weights[obj][2], pred_means[obj][2], pred_std[obj][2], \n",
    "                axes[1], comp=False)\n",
    "axes[1].axvline(x=y_test[obj][2], color='black', alpha=0.5)\n",
    "\n",
    "plot_normal_mix(pred_weights[obj][1], pred_means[obj][1], pred_std[obj][1], \n",
    "                axes[2], comp=False)\n",
    "axes[2].axvline(x=y_test[obj][1], color='black', alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the ensemble by drawing samples of the prediction and plotting the density of those. \n",
    "Seems the MDN learned what it needed too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = sample_from_mixture(X_test, pred_weights, pred_means, \n",
    "                        pred_std, amount=len(X_test))\n",
    "sns.jointplot(a[:,0], a[:,1], kind=\"hex\", color=\"#4CB391\", \n",
    "              ylim=(-10,10), xlim=(-14,14))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thanks\n",
    "\n",
    "Thanks to Dustin Tran for working on this with me. His blog can be found [here](http://dustintran.com/blog/).\n",
    "\n",
    "This entire post was written in an ipython notebook which can be found [here](https://github.com/cbonnett/MDN_Edward_Keras_TF/blob/master/MDN_Edward_Keras_TF.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "from scipy.stats import norm as normal\n",
    "def plot_normal_mix(pis, mus, sigmas, ax, label='', comp=True):\n",
    "    \"\"\"\n",
    "    Plots the mixture of Normal models to axis=ax\n",
    "    comp=True plots all components of mixtur model\n",
    "    \"\"\"\n",
    "    x = np.linspace(-10.5, 10.5, 250)\n",
    "    final = np.zeros_like(x)\n",
    "    for i, (weight_mix, mu_mix, sigma_mix) in enumerate(zip(pis, mus, sigmas)):\n",
    "        temp = normal.pdf(x, mu_mix, sigma_mix) * weight_mix\n",
    "        final = final + temp\n",
    "        if comp:\n",
    "            ax.plot(x, temp, label='Normal ' + str(i))\n",
    "    ax.plot(x, final, label='Mixture of Normals ' + label)\n",
    "    ax.legend(fontsize=13)\n",
    "    \n",
    "def sample_from_mixture(x, pred_weights, pred_means, pred_std, amount):\n",
    "    \"\"\"\n",
    "    Draws samples from mixture model. \n",
    "    Returns 2 d array with input X and sample from prediction of Mixture Model\n",
    "    \"\"\"\n",
    "    samples = np.zeros((amount, 2))\n",
    "    n_mix = len(pred_weights[0])\n",
    "    to_choose_from = np.arange(n_mix)\n",
    "    for j,(weights, means, std_devs) in enumerate(zip(pred_weights, pred_means, pred_std)):\n",
    "        index = np.random.choice(to_choose_from, p=weights)\n",
    "        samples[j,1]= normal.rvs(means[index], std_devs[index], size=1)\n",
    "        samples[j,0]= x[j]\n",
    "        if j == amount -1:\n",
    "            break\n",
    "    return samples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
